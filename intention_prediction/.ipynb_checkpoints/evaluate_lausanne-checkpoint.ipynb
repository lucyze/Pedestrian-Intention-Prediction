{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from attrdict import AttrDict\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sgan.data.loader import data_loader\n",
    "from sgan.models import CNNLSTM1, CNNLSTM2, CNNLSTM3\n",
    "\n",
    "model_path = \"./models/cnnlstm2-vgg16-lausanne-noembedder_with_model.pt\" \n",
    "dataset = \"../dataset/val/lausanne\"\n",
    "\n",
    "def create_folder(directory, renew=False):\n",
    "    \n",
    "    # if directory doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # if already exist, delete and re-create\n",
    "    elif os.path.exists(directory) and renew:\n",
    "        shutil.rmtree(directory)\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_classifier(checkpoint):\n",
    "        \n",
    "    args = AttrDict(checkpoint['args'])  \n",
    "    classifier = CNNLSTM2(\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        h_dim=args.h_dim,\n",
    "        dropout=0.0,\n",
    "        grad=True)\n",
    "    classifier.load_state_dict(checkpoint['best_state'])\n",
    "    return classifier\n",
    "\n",
    "def save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, result):\n",
    "                \n",
    "    create_folder(os.path.join(os.getcwd(), \"results\", result, os.path.basename(pedestrian_foldernames[0][0])))    \n",
    "    for g,foldername,filename in zip(gradients, pedestrian_foldernames[0], pedestrian_filenames[0]):\n",
    "        print(os.path.join(os.getcwd(), \"results\", result, os.path.basename(foldername), filename))\n",
    "        cv2.imwrite(os.path.join(os.getcwd(), \"results\", result, os.path.basename(foldername), filename), np.uint8(g*255))\n",
    "\n",
    "def save_classification(pedestrian_images, decision, pedestrian_filenames, result):\n",
    "    \n",
    "    pedestrian_images = np.transpose(pedestrian_images, axes=(0,2,3,1))\n",
    "        \n",
    "    # get the filename\n",
    "    pedestrian_filenames = [[f.split(\"/\")[-4], f.split(\"/\")[-2], f.split(\"/\")[-1]] for f in pedestrian_filenames] \n",
    "    # create folder for pedestrian\n",
    "    create_folder(os.path.join(os.getcwd(), \"results\", pedestrian_filenames[0][0], result, pedestrian_filenames[0][1]))\n",
    "    \n",
    "    for i,f,d in zip(pedestrian_images, pedestrian_filenames,decision):\n",
    "        print(f, d, result)\n",
    "        cv2.imwrite(os.path.join(os.getcwd(), \"results\", f[0], result, f[1], f[2][0:-4]+\"-\"+str(d)+\".png\"), np.uint8(i*255))\n",
    "        \n",
    "def guidedbackprop(args, loader, classifier):\n",
    "       \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "        \n",
    "    classifier.train()        \n",
    "    for batch in loader:\n",
    "\n",
    "        (pedestrian_crops, decision_true, pedestrian_foldernames, pedestrian_filenames) = batch\n",
    "        \n",
    "        print(decision_true.item())\n",
    "        \n",
    "        # (str(pedestrian_foldernames[0][0]) == \"crops/Ouchy-2-Left/0000000133\")\n",
    "        # (str(pedestrian_foldernames[0][0]) == \"crops/Ouchy-2-Left/0000000159\")\n",
    "        if(0):\n",
    "            \n",
    "            decision_pred_scores = classifier(pedestrian_crops, input_as_var=True, classify_every_timestep=False)        \n",
    "            if(torch.cuda.is_available()):\n",
    "                decision_onehot = torch.cuda.FloatTensor(1, decision_pred_scores.size()[-1]).zero_()\n",
    "            else:\n",
    "                decision_onehot = torch.FloatTensor(1, decision_pred_scores.size()[-1]).zero_()\n",
    "            decision_onehot[0][decision_pred_scores.max(1)[1]] = 1\n",
    "            if(torch.cuda.is_available()):\n",
    "                decision_onehot = decision_onehot.cuda()\n",
    "            else:\n",
    "                decision_onehot = decision_onehot\n",
    "                \n",
    "            # backprop\n",
    "            classifier.zero_grad()\n",
    "            decision_pred_scores.backward(gradient=decision_onehot)\n",
    "            gradients = classifier.gradients.cpu().numpy()\n",
    "\n",
    "            # normalize each image\n",
    "            gradients_min = np.amin(np.reshape(gradients, newshape=(np.shape(gradients)[0],-1)), 1)\n",
    "            gradients_max = np.amax(np.reshape(gradients, newshape=(np.shape(gradients)[0],-1)), 1)\n",
    "            gradients -= gradients_min[:,None,None,None]\n",
    "            gradients /= gradients_max[:,None,None,None] - gradients_min[:,None,None,None]\n",
    "            gradients = np.transpose(gradients, (0, 2, 3, 1))\n",
    "\n",
    "            # save images to folder\n",
    "            decision_true = decision_true.item()\n",
    "            decision_pred = decision_pred_scores.max(1)[1].item()\n",
    "\n",
    "            print(str(pedestrian_foldernames[0][0]), decision_pred, decision_true)\n",
    "            \n",
    "            # tn\n",
    "            if(decision_pred == 0 and decision_true == 0):\n",
    "                tn+=1\n",
    "                #save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"tn\")            \n",
    "            # fn\n",
    "            if(decision_pred == 0 and decision_true == 1):\n",
    "                fn+=1\n",
    "                #save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"fn\")            \n",
    "            # fp\n",
    "            if(decision_pred == 1 and decision_true == 0):\n",
    "                fp+=1\n",
    "                #save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"fp\")            \n",
    "            # tp\n",
    "            if(decision_pred == 1 and decision_true == 1):\n",
    "                tp+=1\n",
    "                #save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"tp\")\n",
    "\n",
    "    print(tn,fn,fp,tp)\n",
    "                \n",
    "# only works for batch size of 1\n",
    "def classify_every_timestep(args, loader, classifier):\n",
    "       \n",
    "    # initialize results dict\n",
    "    images_dict = dict()\n",
    "    prediction_dict = dict()\n",
    "        \n",
    "    classifier.eval()        \n",
    "    for batch in loader:\n",
    "\n",
    "        (pedestrian_crops, decision_true, pedestrian_foldernames, pedestrian_filenames) = batch\n",
    "        \n",
    "        # (str(pedestrian_foldernames[0][0]) == \"crops/Ouchy-2-Left/0000000159\") \n",
    "        # (str(pedestrian_foldernames[0][0]) == \"crops/Ouchy-2-Left/0000000133\")\n",
    "        if(1):\n",
    "                         \n",
    "            # predict decision\n",
    "            decision = classifier(pedestrian_crops, input_as_var=False, classify_every_timestep=True)        \n",
    "            decision_true = decision_true.item()\n",
    "            decision_pred = torch.stack(decision).cpu().numpy()[-1]\n",
    "            \n",
    "            # update dict\n",
    "            images_dict[str(pedestrian_foldernames[0][0])] = [str(pedestrian_filenames[0][0])]\n",
    "            prediction_dict[str(pedestrian_foldernames[0][0])] = [decision_pred[0]]\n",
    "            for i in range(1,len(decision_pred)):\n",
    "                images_dict[str(pedestrian_foldernames[0][0])].append(str(pedestrian_filenames[0][i]))\n",
    "                prediction_dict[str(pedestrian_foldernames[0][0])].append(decision_pred[i])\n",
    "        \n",
    "    return images_dict, prediction_dict\n",
    "            \n",
    "def main(args):\n",
    "            \n",
    "    # create results folder if it does not exist\n",
    "    # - used for guidedbackprop\n",
    "    results_root = os.path.join(os.getcwd(), \"results\")\n",
    "    create_folder(results_root, renew=False)\n",
    "    \n",
    "    # model path\n",
    "    path = args.model_path\n",
    "    print(\"model path \", path)\n",
    "\n",
    "     # get the model\n",
    "    checkpoint = torch.load(path, map_location='cpu')\n",
    "    classifier = get_classifier(checkpoint)\n",
    "\n",
    "    # generate the arguments\n",
    "    _args = AttrDict(checkpoint['args']) \n",
    "    _args.batch_size = 1\n",
    "    _args.timestep = 10\n",
    "    print(_args)\n",
    "    input()\n",
    "\n",
    "    # get the dataset\n",
    "    val_path = os.path.join(args.dataset, \"val\") \n",
    "    dset, loader = data_loader(_args, val_path, \"val\")\n",
    "    \n",
    "    print('Running Guided Backprop')\n",
    "    guidedbackprop(_args, loader, classifier)\n",
    "\n",
    "    #print('Classifying at every timestep')\n",
    "    #images_dict, prediction_dict = classify_every_timestep(_args, loader, classifier)\n",
    "    #return images_dict, prediction_dict\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', type=str)\n",
    "    parser.add_argument('--dset_type', default='test', type=str)\n",
    "\n",
    "    parser.model_path = model_path\n",
    "    parser.dataset = dataset #\"./datasets/lausanne\" #\"./datasets/riponne\" lausanne\n",
    "    args = parser\n",
    "    images_dict, prediction_dict = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/riponne/val/annotations/Riponne-Left-final.txt\") \n",
    "for count,((folderpath1, filename), (folderpath2, prediction)) in enumerate(zip(images_dict.items(), prediction_dict.items())):\n",
    "\n",
    "    # get the filenames (images) in the dataframe for the current pedestrian\n",
    "    decision = 0\n",
    "    for f in df.loc[(df[\"folderpath\"] == folderpath1)][\"filename\"]:\n",
    "        # if the image has been given a label by the classifier\n",
    "        if(f in filename):\n",
    "            i = filename.index(f) # index at which the filename occurs\n",
    "            p = prediction[i]     # get the prediction given the index\n",
    "            #print(f, p)\n",
    "            decision = p\n",
    "            df.loc[(df[\"folderpath\"] == folderpath1) & (df[\"filename\"] == f), \"cross_pred\"] = decision\n",
    "        else:\n",
    "            # set it to the previous decision if it is not in the list of predicted images\n",
    "            df.loc[(df[\"folderpath\"] == folderpath1) & (df[\"filename\"] == f), \"cross_pred\"] = decision\n",
    "df.to_csv(\"Riponne.txt\", sep=',', encoding='utf-8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------- args ------- # \n",
    "in_video    = \"./datasets/lausanne/val/videos/Ouchy-2-Left-cropped.MP4\" \n",
    "op_video    = in_video[0:-4] + \"-pred.MP4\"    # \"./videos/23-10-2018/Ouchy-2-Left-cropped-pred.MP4\"\n",
    "annotations = \"./Ouchy-last-timestep.txt\"\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX;\n",
    "scale = 0.4;\n",
    "thickness = 1;\n",
    "baseline = 0;\n",
    "\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "# ------- args ------- #\n",
    "\n",
    "# ------- main ------- #\n",
    "df = pd.read_csv(annotations)\n",
    "\n",
    "in_cap = cv2.VideoCapture(in_video)\n",
    "op_cap = cv2.VideoWriter(op_video, cv2.VideoWriter_fourcc(*'XVID'), 30, (int(in_cap.get(3)),int(in_cap.get(4))))\n",
    "       \n",
    "print(\"Drawing trajectories\")\n",
    "pbar = tqdm(total = df[\"frame\"].max())\n",
    "t = 1\n",
    "while(in_cap.isOpened()):\n",
    "            \n",
    "    pbar.update(1)\n",
    "\n",
    "    #if(t==df[\"frame\"].max()):\n",
    "    #    break\n",
    "    \n",
    "    # get frame\n",
    "    ret, im1 = in_cap.read()\n",
    "    im = np.copy(im1)\n",
    "    if(ret==False):\n",
    "        break\n",
    "\n",
    "    for row in df[df[\"frame\"] == t].itertuples(index=True, name='Pandas'):        \n",
    "        #if((row.height <= 50) or (row.tly + row.height + 40 > np.shape(im)[0])):\n",
    "        # red box for crossing\n",
    "        if(row.cross_pred != -1):# and row.x > min_lifetime_crossers):\n",
    "                    \n",
    "            # put ground truth\n",
    "            #label = \"true: \" + str(row.cross_true)\n",
    "            #text = cv2.getTextSize(label, fontface, scale, thickness);\n",
    "            #cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.height+row.tly-20), (x_offset+row.tlx+row.width+20, y_offset+row.height+row.tly-10), (0,0,0), -1);\n",
    "            #cv2.putText(im, label, (x_offset+row.tlx, y_offset+row.height+row.tly-10), fontface, scale, (255,255,255), thickness, 8);\n",
    "                    \n",
    "            # put prediction\n",
    "            #label = \"pred: \" + str(row.cross_pred)\n",
    "            #text = cv2.getTextSize(label, fontface, scale, thickness);\n",
    "            #cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.height+row.tly-10), (x_offset+row.tlx+row.width+20, y_offset+row.height+row.tly), (0,0,0), -1);\n",
    "            #cv2.putText(im, label, (x_offset+row.tlx, y_offset+row.height+row.tly), fontface, scale, (255,255,255), thickness, 8);            \n",
    "            \n",
    "            # put ID\n",
    "            #label = str(row.id)\n",
    "            #text = cv2.getTextSize(label, fontface, scale, thickness);\n",
    "            #cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.tly+row.height), (x_offset+row.tlx+row.width+20, y_offset+row.tly+row.height+10), (0,0,0), -1);\n",
    "            #cv2.putText(im, label, (x_offset+row.tlx, y_offset+row.tly+row.height+10), fontface, scale, (255,255,255), thickness, 8);  \n",
    "                    \n",
    "            # draw bounding box\n",
    "            if(row.cross_pred == 1):\n",
    "                cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.tly), (x_offset+row.tlx+row.width, y_offset+row.tly+row.height), color=(0, 0, 255), thickness=2)\n",
    "            \n",
    "            if(row.cross_pred == 0):\n",
    "                cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.tly), (x_offset+row.tlx+row.width, y_offset+row.tly+row.height), color=(0, 255, 0), thickness=2)\n",
    "                   \n",
    "    op_cap.write(im)\n",
    "    t+=1\n",
    "    #if(t==100):\n",
    "    #    break\n",
    "    \n",
    "in_cap.release()\n",
    "op_cap.release() \n",
    "# ------- main ------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------- args ------- # \n",
    "in_video    = \"./datasets/riponne/val/videos/Riponne-Left-cropped.MP4\" \n",
    "op_video    = in_video[0:-4] + \"-pred.MP4\"    # \"./videos/23-10-2018/Ouchy-2-Left-cropped-pred.MP4\"\n",
    "annotations = \"./Riponne.txt\"\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX;\n",
    "scale = 0.4;\n",
    "thickness = 1;\n",
    "baseline = 0;\n",
    "\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "# ------- args ------- #\n",
    "\n",
    "# ------- main ------- #\n",
    "df = pd.read_csv(annotations)\n",
    "\n",
    "in_cap = cv2.VideoCapture(in_video)\n",
    "op_cap = cv2.VideoWriter(op_video, cv2.VideoWriter_fourcc(*'XVID'), 30, (int(in_cap.get(3)),int(in_cap.get(4))))\n",
    "       \n",
    "print(\"Drawing trajectories\")\n",
    "pbar = tqdm(total = df[\"frame\"].max())\n",
    "t = 1\n",
    "while(in_cap.isOpened()):\n",
    "            \n",
    "    pbar.update(1)\n",
    "\n",
    "    #if(t==df[\"frame\"].max()):\n",
    "    #    break\n",
    "    \n",
    "    # get frame\n",
    "    ret, im1 = in_cap.read()\n",
    "    im = np.copy(im1)\n",
    "    if(ret==False):\n",
    "        break\n",
    "\n",
    "    for row in df[df[\"frame\"] == t].itertuples(index=True, name='Pandas'):        \n",
    "        #if((row.height <= 50) or (row.tly + row.height + 40 > np.shape(im)[0])):\n",
    "        # red box for crossing\n",
    "        if(row.cross_pred != -1):# and row.x > min_lifetime_crossers):\n",
    "                    \n",
    "            # put ground truth\n",
    "            #label = \"true: \" + str(row.cross_true)\n",
    "            #text = cv2.getTextSize(label, fontface, scale, thickness);\n",
    "            #cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.height+row.tly-20), (x_offset+row.tlx+row.width+20, y_offset+row.height+row.tly-10), (0,0,0), -1);\n",
    "            #cv2.putText(im, label, (x_offset+row.tlx, y_offset+row.height+row.tly-10), fontface, scale, (255,255,255), thickness, 8);\n",
    "                    \n",
    "            # put prediction\n",
    "            #label = \"pred: \" + str(row.cross_pred)\n",
    "            #text = cv2.getTextSize(label, fontface, scale, thickness);\n",
    "            #cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.height+row.tly-10), (x_offset+row.tlx+row.width+20, y_offset+row.height+row.tly), (0,0,0), -1);\n",
    "            #cv2.putText(im, label, (x_offset+row.tlx, y_offset+row.height+row.tly), fontface, scale, (255,255,255), thickness, 8);            \n",
    "            \n",
    "            # put ID\n",
    "            #label = str(row.id)\n",
    "            #text = cv2.getTextSize(label, fontface, scale, thickness);\n",
    "            #cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.tly+row.height), (x_offset+row.tlx+row.width+20, y_offset+row.tly+row.height+10), (0,0,0), -1);\n",
    "            #cv2.putText(im, label, (x_offset+row.tlx, y_offset+row.tly+row.height+10), fontface, scale, (255,255,255), thickness, 8);  \n",
    "                    \n",
    "            # draw bounding box\n",
    "            if(row.cross_pred == 1):\n",
    "                cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.tly), (x_offset+row.tlx+row.width, y_offset+row.tly+row.height), color=(0, 0, 255), thickness=2)\n",
    "            \n",
    "            if(row.cross_pred == 0):\n",
    "                cv2.rectangle(im, (x_offset+row.tlx, y_offset+row.tly), (x_offset+row.tlx+row.width, y_offset+row.tly+row.height), color=(0, 255, 0), thickness=2)\n",
    "                   \n",
    "    op_cap.write(im)\n",
    "    t+=1\n",
    "    #if(t==100):\n",
    "    #    break\n",
    "    \n",
    "in_cap.release()\n",
    "op_cap.release() \n",
    "# ------- main ------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/cnnlstm2-vgg16-lausanne-noembedder_with_model.pt\", map_location='cpu')\n",
    "print(checkpoint['best_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in checkpoint.items() :\n",
    "    print(key)\n",
    "    \n",
    "print(checkpoint['best_t'])\n",
    "for key, value in checkpoint['best_state'].items() :\n",
    "    if(key == \"lstm.weight_hh_l0\"):\n",
    "        a = value\n",
    "        \n",
    "for name, param in classifier.named_parameters():\n",
    "    if(name == \"lstm.weight_hh_l0\"):\n",
    "        b = param\n",
    "for name, param in classifier.named_parameters():\n",
    "    print(name)\n",
    "print(np.linalg.norm((a-b).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in classifier.named_children():\n",
    "    #if(p == 'lstm'):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['metrics_val']['d_precision'][57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "checkpoint = torch.load(\"./models/ckpt_with_model.pt\", map_location='cpu')\n",
    "plt.figure()\n",
    "plt.title(\"loss\")\n",
    "plt.plot(checkpoint['metrics_train']['d_loss'], 'r', checkpoint['metrics_val']['d_loss'], 'b')\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.figure()\n",
    "plt.title(\"precision\")\n",
    "plt.plot(checkpoint['metrics_train']['d_precision'], 'r', checkpoint['metrics_val']['d_precision'], 'b')\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.figure()\n",
    "plt.title(\"recall\")\n",
    "plt.plot(checkpoint['metrics_train']['d_recall'], 'r', checkpoint['metrics_val']['d_recall'], 'b')\n",
    "plt.legend([\"train\", \"val\"])\n",
    "\n",
    "print(che)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./vgg16-lausanne.pt\", map_location='cpu')\n",
    "print(checkpoint['best_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./vgg16-lausanne.pt\", map_location='cpu')\n",
    "print(checkpoint['best_state'])\n",
    "plt.figure()\n",
    "plt.title(\"loss\")\n",
    "plt.plot(checkpoint['metrics_train']['d_loss'], 'r', checkpoint['metrics_val']['d_loss'], 'b')\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.figure()\n",
    "plt.title(\"precision\")\n",
    "plt.plot(checkpoint['metrics_train']['d_precision'], 'r', checkpoint['metrics_val']['d_precision'], 'b')\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.figure()\n",
    "plt.title(\"recall\")\n",
    "plt.plot(checkpoint['metrics_train']['d_recall'], 'r', checkpoint['metrics_val']['d_recall'], 'b')\n",
    "plt.legend([\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Ouch.txt\")\n",
    "df = df[(df[\"folderpath\"] == \"crops/Ouchy-2-Left/0000000645\") & (df[\"cross_pred\"] == 1)]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
