{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from attrdict import AttrDict\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sgan.data.loader import data_loader\n",
    "from sgan.models import CNNLSTM1, CNNLSTM2, CNNLSTM3\n",
    "\n",
    "model_path = \"./models/cnnlstm2-vgg16-lausanne-noembedder_with_model.pt\" \n",
    "dataset = \"./datasets/lausanne\"\n",
    "\n",
    "def create_folder(directory, renew=False):\n",
    "    \n",
    "    # if directory doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # if already exist, delete and re-create\n",
    "    elif os.path.exists(directory) and renew:\n",
    "        shutil.rmtree(directory)\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_classifier(checkpoint):\n",
    "        \n",
    "    args = AttrDict(checkpoint['args'])  \n",
    "    classifier = CNNLSTM2(\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        h_dim=args.h_dim,\n",
    "        dropout=0.0,\n",
    "        grad=True)\n",
    "    classifier.load_state_dict(checkpoint['best_state'])\n",
    "    return classifier\n",
    "\n",
    "def save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, result):\n",
    "                \n",
    "    create_folder(os.path.join(os.getcwd(), \"results\", result, os.path.basename(pedestrian_foldernames[0][0])))    \n",
    "    for g,foldername,filename in zip(gradients, pedestrian_foldernames[0], pedestrian_filenames[0]):\n",
    "        print(os.path.join(os.getcwd(), \"results\", result, os.path.basename(foldername), filename))\n",
    "        cv2.imwrite(os.path.join(os.getcwd(), \"results\", result, os.path.basename(foldername), filename), np.uint8(g*255))\n",
    "\n",
    "def guidedbackprop(args, loader, classifier):\n",
    "       \n",
    "    classifier.train()        \n",
    "    for batch in loader:\n",
    "\n",
    "        (pedestrian_crops, decision_true, pedestrian_foldernames, pedestrian_filenames) = batch\n",
    "        \n",
    "        # (str(pedestrian_foldernames[0][0]) == \"crops/Ouchy-2-Left/0000000133\")\n",
    "        # (str(pedestrian_foldernames[0][0]) == \"crops/Ouchy-2-Left/0000000159\")\n",
    "        if(1):\n",
    "            \n",
    "            decision_pred_scores = classifier(pedestrian_crops, input_as_var=True, classify_every_timestep=False)        \n",
    "            if(torch.cuda.is_available()):\n",
    "                decision_onehot = torch.cuda.FloatTensor(1, decision_pred_scores.size()[-1]).zero_()\n",
    "            else:\n",
    "                decision_onehot = torch.FloatTensor(1, decision_pred_scores.size()[-1]).zero_()\n",
    "            decision_onehot[0][decision_pred_scores.max(1)[1]] = 1\n",
    "            if(torch.cuda.is_available()):\n",
    "                decision_onehot = decision_onehot.cuda()\n",
    "            else:\n",
    "                decision_onehot = decision_onehot\n",
    "                \n",
    "            # backprop\n",
    "            classifier.zero_grad()\n",
    "            decision_pred_scores.backward(gradient=decision_onehot)\n",
    "            gradients = classifier.gradients.cpu().numpy()\n",
    "\n",
    "            # normalize each image\n",
    "            gradients_min = np.amin(np.reshape(gradients, newshape=(np.shape(gradients)[0],-1)), 1)\n",
    "            gradients_max = np.amax(np.reshape(gradients, newshape=(np.shape(gradients)[0],-1)), 1)\n",
    "            gradients -= gradients_min[:,None,None,None]\n",
    "            gradients /= gradients_max[:,None,None,None] - gradients_min[:,None,None,None]\n",
    "            gradients = np.transpose(gradients, (0, 2, 3, 1))\n",
    "\n",
    "            # save images to folder\n",
    "            decision_true = decision_true.item()\n",
    "            decision_pred = decision_pred_scores.max(1)[1].item()\n",
    "\n",
    "            # tn\n",
    "            if(decision_pred == 0 and decision_true == 0):\n",
    "                save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"tn\")            \n",
    "            # fn\n",
    "            if(decision_pred == 0 and decision_true == 1):\n",
    "                save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"fn\")            \n",
    "            # fp\n",
    "            if(decision_pred == 1 and decision_true == 0):\n",
    "                save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"fp\")            \n",
    "            # tp\n",
    "            if(decision_pred == 1 and decision_true == 1):\n",
    "                save_gradients(gradients, pedestrian_foldernames, pedestrian_filenames, \"tp\")\n",
    "            \n",
    "def main(args):\n",
    "            \n",
    "    # create results folder if it does not exist\n",
    "    # - used for guidedbackprop\n",
    "    results_root = os.path.join(os.getcwd(), \"results\")\n",
    "    create_folder(results_root, renew=False)\n",
    "    \n",
    "    # model path\n",
    "    path = args.model_path\n",
    "    print(\"model path \", path)\n",
    "\n",
    "     # get the model\n",
    "    checkpoint = torch.load(path, map_location='cpu')\n",
    "    classifier = get_classifier(checkpoint)\n",
    "\n",
    "    # generate the arguments\n",
    "    _args = AttrDict(checkpoint['args']) \n",
    "    _args.batch_size = 1\n",
    "    print(_args)\n",
    "\n",
    "    # get the dataset\n",
    "    val_path = os.path.join(args.dataset, \"val\") \n",
    "    dset, loader = data_loader(_args, val_path, \"val\")\n",
    "    \n",
    "    print('Running Guided Backprop')\n",
    "    guidedbackprop(_args, loader, classifier)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', type=str)\n",
    "    parser.add_argument('--dset_type', default='val', type=str)\n",
    "\n",
    "    parser.model_path = model_path\n",
    "    parser.dataset = dataset #\"./datasets/lausanne\" #\"./datasets/riponne\" lausanne\n",
    "    args = parser\n",
    "    images_dict, prediction_dict = main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
